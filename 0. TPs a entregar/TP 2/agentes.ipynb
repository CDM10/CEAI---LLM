{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9210a8-8499-4c70-a6c5-dd7c12abc981",
   "metadata": {},
   "source": [
    "## Se utilizara la base de datos vectorial de Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e9e57-5a02-44b8-af19-f292dc4f24a1",
   "metadata": {},
   "source": [
    "### Procesamiento de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13a0681-dc03-4ebb-bc72-d84cf91921be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9977a46b-3256-4318-b4cc-2287c87d75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los chunks\n",
    "def chunkData(docs, chunk_size=100, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625c9c2-860a-4878-9483-4848e1a0b2ec",
   "metadata": {},
   "source": [
    "Uso 2 CVs, el de mi traumatologo y el mio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf8604e-c511-476a-ad45-3bd77dd4cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Cargo los documentos \n",
    "miCV = \"./CV_CristianMarino_CEIA_LLM.pdf\"\n",
    "jorgeCV = \"./CV-JorgeBoretto.pdf\"\n",
    "\n",
    "cloader = PyPDFLoader(miCV)\n",
    "cdocs = cloader.load()\n",
    "\n",
    "jloader = PyPDFLoader(jorgeCV)\n",
    "jdocs = jloader.load()\n",
    "\n",
    "# Genero los chunks \n",
    "cchunks = chunkData(cdocs, chunk_size=500, chunk_overlap=100)\n",
    "jchunks = chunkData(jdocs, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2bd31-5b04-4bdc-8a07-4af02f086e1a",
   "metadata": {},
   "source": [
    "### Generación de embbeding y carga en base de datos vectorial\n",
    "Se utilizara un indice por cada uno de los cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc532d10-6cd5-46e1-956b-a77287855eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dd8573-5ecf-460b-9ca8-cbb17381256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='1.env')\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41be9cb0-d296-4dbe-98d1-c8d2cc9f1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to DB Pinecone\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "cloud = 'aws'\n",
    "region = 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "indices = ['cagent', 'jagent']\n",
    "namespace = \"espacio\"\n",
    "dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a8ebbe-ddb5-4c5b-8885-850c370df084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ragllm', 'tp2llm', 'jagent', 'cagent']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bfce94-c977-4120-9af6-f6a4ce60537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index cagent borrado\n",
      "index creado con el nombre: cagent\n",
      "index jagent borrado\n",
      "index creado con el nombre: jagent\n"
     ]
    }
   ],
   "source": [
    "# Elimino el indice si es que ya existe en la base de datos\n",
    "for index_name in indices:\n",
    "    if index_name in pc.list_indexes().names():\n",
    "      pc.delete_index(index_name)\n",
    "      print(\"index {} borrado\".format(index_name))\n",
    "    \n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        # Como lo borre en el paso anterior siempre deberia entrar aca\n",
    "        print(\"index creado con el nombre: {}\".format(index_name))\n",
    "        pc.create_index(\n",
    "            index_name,\n",
    "            dimension=dimension, \n",
    "            metric='cosine',\n",
    "            spec=spec\n",
    "            )\n",
    "    else:\n",
    "        print(\"el index con el nombre {} ya estaba creado\".format(index_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3075029-aa98-4b1b-8c75-df90ab08c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Intel Core I5 10400\\AppData\\Local\\Temp\\ipykernel_10780\\1365815625.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Cargo un modelo de embeddings compatible\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2ec3d1-f0ff-4178-bd68-090202ae7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upserted values to 'cagent' index\n"
     ]
    }
   ],
   "source": [
    "# Cargo chunks en base de datos\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=cchunks,\n",
    "    index_name='cagent',\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(\"upserted values to 'cagent' index\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad50f96-4b6f-4e22-b744-b612fe8b71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upserted values to 'jagent' index\n"
     ]
    }
   ],
   "source": [
    "# Cargo chunks en base de datos\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=jchunks,\n",
    "    index_name='jagent',\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(\"upserted values to 'jagent' index\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe953b8-c08a-4a6d-b2ac-edb1a8bc96db",
   "metadata": {},
   "source": [
    "### Busquedas en base de datos\n",
    "\n",
    "Realizo pruebas para verificar que los datos se guardaron correctamente\n",
    "\n",
    "## CRISTIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c878cd-d998-49e0-8d60-b1d02b900806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'espacio': {'vector_count': 9}},\n",
       " 'total_vector_count': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(indices[0])\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e78205-8240-4610-a6a9-1125930d79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=indices[0],\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8426fd24-c1b0-42bf-b4de-f4a6a5e914fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='02a1ebc7-30b3-4e0f-adcc-d8d30ccfe349', metadata={'page': 0.0, 'source': './CV_CristianMarino_CEIA_LLM.pdf'}, page_content='PYTHON                                  \\nPOWER BI                                \\nSenior Project Manager                                         Oct 2023 - Today\\nFECOVITA| Argentina\\nPMO Leader. Responsible for CAPEX portfolio management.\\nFormulation, feasibility study, bidding, execution and final audit of projects,\\nPresentation of Investment opportunities and funding proposals to the Board.\\nAchievements: 5 pre-approved projects. Currently, under bidding,\\nWORK EXPERIENCE'),\n",
       " Document(id='ccde11a9-8292-4282-9078-7ae674e80d5b', metadata={'page': 0.0, 'source': './CV_CristianMarino_CEIA_LLM.pdf'}, page_content='cristian.dam.marino@gmail.com\\n+ 54 9 2616504324\\nMendoza, Argentina\\nLANGUAGES AND TECH SKILLS\\nENGLISH                                                  (C1)\\nPORTUGUESE                                        (B2)\\nFRENCH                                                  (B1)\\nITALIAN                                                   (B1)\\nSQL                                           \\nPYTHON                                  \\nPOWER BI'),\n",
       " Document(id='1bf3fe03-9a29-4caf-972f-e04da3f3a842', metadata={'page': 0.0, 'source': './CV_CristianMarino_CEIA_LLM.pdf'}, page_content='vision, time series analysis, natural language processing and big data.\\nEDUCATION\\nMEng in Industrial Engineering                                                 2022 \\nUniversidad Nacional de Cuyo | Argentina\\nExchange programs in Chile and Bolivia. Volunteering experience in Brazil.\\nVP of Finance and Legal                                  Aug 2019 - Jul 2020\\nThe AIESEC Foundation | Chile\\nResponsible for overall legal, financial and audit management and strategy,')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Qué hace en Fecovita\"\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d90c9a-ecdf-4d61-a458-b70861e24ca8",
   "metadata": {},
   "source": [
    "#### Jorge Boretto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b270a5c7-3e99-4d6f-8568-a3eed7346c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'espacio': {'vector_count': 9}},\n",
       " 'total_vector_count': 9}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(indices[0])\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b08cdacb-ef12-4f7b-9e1f-899dab38f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvectorstore = PineconeVectorStore(\n",
    "    index_name=indices[1],\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=jvectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3497870-b84b-42a6-b416-1d452e63f97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='85558b05-ed92-40b4-a4a4-50b9e7252f8a', metadata={'page': 26.0, 'source': './CV-JorgeBoretto.pdf'}, page_content='y Matemáticas. Secretaría de Graduados en Ciencias de la Salud, Universidad Nacional de Córdoba. Duración 20 hs. (aprobado). Córdoba, Argentina.  IDIOMA  Francés - 05.2003. Curso de Francés Aprobado. Cours de Langue 1 de Français Langue Etrangère. Alliance Française de Córdoba. Duración 39 hs. Córdoba, Argentina.  Ingles - 12.2002. Examen de Inglés Aprobado. Secretaría de Graduados en Ciencias de la Salud, Universidad Nacional de Córdoba. Córdoba, Argentina. - 03.1999. Educación Continua de'),\n",
       " Document(id='91475b1f-a390-408b-b915-ff60967f46fb', metadata={'page': 9.0, 'source': './CV-JorgeBoretto.pdf'}, page_content='para Cobertura de Grandes Defectos en Mano”. 38º Congreso Argentino de Cirugía de la Mano. Mar del Plata, Argentina.  AÑO 2011 ü “Colgajos en Isla de la Mano”. Simposio: “Colgajos en el Miembro Superior”. 48° Congreso Argentino de Ortopedia y Traumatología. Buenos Aires, Argentina. ü “Lesiones de Plexo Braquial”. III Curso de Revisión en Ortopedia General. 48° Congreso Argentino de Ortopedia y Traumatología. Buenos Aires, Argentina. ü “¿Cómo Publicar?”. Curso de Instrucción Práctica: ¿Qué es'),\n",
       " Document(id='2a28fc58-48a3-49a4-99f5-38a3d62b56a2', metadata={'page': 26.0, 'source': './CV-JorgeBoretto.pdf'}, page_content='Argentina. ü III Jornadas de Educación para Profesionales de la Salud: “Nuevas Tecnologías para la formación en Salud”. Hospital Italiano de Buenos Aires. Buenos Aires, Argentina. ü Curso: “Preparación, diseño y presentación de un trabajo científico”. Asociación Argentina de Cirugía de la Mano y Reconstructiva del Miembro Superior. Buenos Aires, Argentina.  AÑO 2007 ü Curso de Postgrado de Epidemiología y Estadística. Instituto Universitario, Escuela de Medicina del Hospital Italiano. Duración')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cuales es su educacion?\"\n",
    "jvectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edea2d-fc41-4c4b-a1f6-eed59329529a",
   "metadata": {},
   "source": [
    "## Agente LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229bde6f-a3e0-43fc-ab95-01fc3420c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (0.2.59)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph) (0.3.24)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph) (2.0.9)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph) (0.1.44)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.2.3)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\intel core i5 10400\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
      "Requirement already satisfied: anyio in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad56ff5-490d-47af-a661-0854ae7e8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1624e699-7d8a-4742-9715-48e17aea6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0766d7b4-ad29-4acb-8eaf-6b522ff6e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY, \n",
    "    model_name='llama3-8b-8192'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af742fa-c7d6-4538-86e4-2207020f9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una clase para guardar el estado \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    individual: str\n",
    "    history: List[str] \n",
    "\n",
    "# Defino un tamplate para el prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"individual\"],\n",
    "    template=\"\"\"\n",
    "Eres un asistente para tareas de preguntas y respuestas. Usa los siguientes fragmentos de historia y contexto recuperados para responder la pregunta respecto al individuo.\n",
    "Si no sabes la respuesta, di que no lo sabes. Usa un máximo de 200 palabras y mantén la respuesta concisa. \n",
    "---\n",
    "Historia:\n",
    "{history}\n",
    "---\n",
    "Contexto:\n",
    "{context}\n",
    "---\n",
    "Individuo:\n",
    "{individual}\n",
    "---\n",
    "Pregunta: {question}\n",
    "Respuesta:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Defino una clase agente para hacer la busqueda en la base vectorial segun la persona\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, embedding_model, index=\"\"):\n",
    "        if index==\"\":\n",
    "            raise ValueError(\"No se especifico un índice válido.\")\n",
    "        \n",
    "        self.index = index\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        self.vectorstore = PineconeVectorStore(\n",
    "            index_name=index,\n",
    "            embedding=self.embedding_model,\n",
    "            namespace=namespace,\n",
    "        )\n",
    "\n",
    "    def get_context(self,state: State):\n",
    "        retrieved_docs = self.vectorstore.similarity_search(state[\"question\"],k=2)\n",
    "        return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "832b4a22-0005-46ad-ace7-cdff1c943310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio agentes\n",
    "cagent = Agent(embedding_model,\"cagent\")\n",
    "jagent = Agent(embedding_model,\"jagent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bb6f15d-edce-42d0-a318-b48610cb31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los nodos para el agente\n",
    "def generate(state: State):\n",
    "    if state[\"context\"]:\n",
    "        docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    else: \n",
    "        docs_content = \"\"\n",
    "    # Formateo la historia como un unico string\n",
    "    history = \"\\n\".join(state[\"history\"])\n",
    "    \n",
    "    # Invoco el prompt con contexto e historia previa\n",
    "    messages = prompt.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content,\n",
    "        \"individual\": state[\"individual\"],\n",
    "        \"history\": history\n",
    "    })\n",
    "\n",
    "    # print(messages)\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    state[\"history\"].append(f\"Q: {state['question']} A: {response.content}\")\n",
    "    \n",
    "    # Ahora ya es posible devolver la respuesta\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Nodo para limpiar el contexto\n",
    "def empty_context(state:State):\n",
    "    return {\"context\":[]}\n",
    "\n",
    "# Segun sobre a quien se refiere la pregunta se utiliza un agente u otro\n",
    "def decide(state: State):\n",
    "    \n",
    "    cristian_pattern = r\"(Cristian\\sMarino|Cristian|Marino)\"\n",
    "    jorge_pattern = r\"(Jorge\\sBoretto|Jorge|Boretto)\"\n",
    "    individual = \"\" \n",
    "    \n",
    "    if re.search(cristian_pattern, state[\"question\"], re.IGNORECASE):\n",
    "        individual = \"cristian\"\n",
    "    elif re.search(jorge_pattern, state[\"question\"], re.IGNORECASE):\n",
    "        individual = \"jorge\"\n",
    "    return {\"individual\":individual}\n",
    "\n",
    "# Funcion para determinar cuál es el próximo nodo\n",
    "def decision_read_state(state:State):\n",
    "    \"\"\"Obtiene el individuo desde el state y lo retorna para decidir por qué nodo continuar.\"\"\"\n",
    "    indiv = state[\"individual\"]\n",
    "    if indiv==\"\":\n",
    "        print(\"La pregunta no habla de ningun individuo.\")\n",
    "        return \"no_individual\"\n",
    "    print(\"La pregunta habla sobre el individuo:\",indiv)\n",
    "    return indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4d0da0-12f0-483c-8e45-537a964026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo el grafo de nodos\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"decision\",decide)\n",
    "graph_builder.add_node(\"cristian_agent\",cagent.get_context)\n",
    "graph_builder.add_node(\"jorge_agent\",jagent.get_context)\n",
    "graph_builder.add_node(\"generate\",generate)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"decision\",\n",
    "    decision_read_state,\n",
    "    {\"cristian\": \"cristian_agent\",\"jorge\": \"jorge_agent\",\"no_individual\":\"cristian_agent\"}\n",
    "    )\n",
    "graph_builder.add_edge(\"cristian_agent\",\"generate\")\n",
    "graph_builder.add_edge(\"jorge_agent\",\"generate\")\n",
    "graph_builder.set_entry_point(\"decision\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4811-86f8-4630-8a46-1b32d495305a",
   "metadata": {},
   "source": [
    "## No me sale usar graph viz, ni json, ni networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc52747-75f7-4953-8276-f77df905d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dot(graph):\n",
    "    dot_representation = 'digraph G {\\n'\n",
    "    for node_id, node in graph.nodes.items():\n",
    "        dot_representation += f'    \"{node_id}\"\\n'\n",
    "    for edge in graph.edges:\n",
    "        if edge.conditional:\n",
    "            dot_representation += f'    \"{edge.source}\" -> \"{edge.target}\" [label=\"{edge.data}\"]\\n'\n",
    "        else:\n",
    "            dot_representation += f'    \"{edge.source}\" -> \"{edge.target}\"\\n'\n",
    "    dot_representation += '}'\n",
    "    return dot_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2aa1dc8-687d-482a-b9bf-5369139b391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph G {\n",
      "    \"__start__\"\n",
      "    \"decision\"\n",
      "    \"cristian_agent\"\n",
      "    \"jorge_agent\"\n",
      "    \"generate\"\n",
      "    \"__start__\" -> \"decision\"\n",
      "    \"cristian_agent\" -> \"generate\"\n",
      "    \"jorge_agent\" -> \"generate\"\n",
      "    \"decision\" -> \"cristian_agent\" [label=\"cristian\"]\n",
      "    \"decision\" -> \"jorge_agent\" [label=\"jorge\"]\n",
      "    \"decision\" -> \"cristian_agent\" [label=\"no_individual\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Este formato lo utilizo en la pagina web para generar el grafico\n",
    "print(convert_to_dot(graph.get_graph()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91565557-0e03-44ac-9d30-58230bece17b",
   "metadata": {},
   "source": [
    "### Prueba del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9684f2d7-74b9-45b3-81a9-2375c31052c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta habla sobre el individuo: jorge\n",
      "Sí, Jorge Boretto es médico, según se menciona en su perfil que trabaja en la Clínica de la Mano de Buenos Aires.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Jorge es médico?\",\"history\":[]})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b75dc26-0851-4000-88cf-967cd567b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta habla sobre el individuo: cristian\n",
      "Cristian tiene experiencia en gestión general de legal, financiera y de auditoría, y ha liderado 6 equipos. Ha trabajado con múltiples stakeholders y ha sido representante de la oficina chilena ante el Consejo Financiero de la Sede Central. Además, ha logrado varios logros notables, como la renegociación de 5 contratos clave que llevó a un crecimiento del 28% en la renta y un aumento de los reservas financieras en un 450%. También ha reducido el tiempo de cobro en 23 días.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Contame sobre la experiencia de Cristian\",\"history\":[]})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f1341d-2f6d-4c6f-b4b0-34bc1baae500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta no habla de ningun individuo.\n",
      "No tengo información sobre el lugar de trabajo actual del individuo. Sin embargo, puedo mencionar que en el pasado fue VP de Finance and Legal en The AIESEC Foundation en Chile, desde agosto de 2019 hasta julio de 2020.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Dónde trabaja?\",\"history\":[]})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb6036-cead-4b84-a5e1-8d65b1940ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
