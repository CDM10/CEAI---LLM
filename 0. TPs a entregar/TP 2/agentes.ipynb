{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9210a8-8499-4c70-a6c5-dd7c12abc981",
   "metadata": {},
   "source": [
    "## Se utilizara la base de datos vectorial de Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e9e57-5a02-44b8-af19-f292dc4f24a1",
   "metadata": {},
   "source": [
    "### Procesamiento de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13a0681-dc03-4ebb-bc72-d84cf91921be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9977a46b-3256-4318-b4cc-2287c87d75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los chunks\n",
    "def chunkData(docs, chunk_size=100, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625c9c2-860a-4878-9483-4848e1a0b2ec",
   "metadata": {},
   "source": [
    "Uso 2 CVs, el de mi traumatologo y el mio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf8604e-c511-476a-ad45-3bd77dd4cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Cargo los documentos \n",
    "miCV = \"./CV_CristianMarino_CEIA_LLM.pdf\"\n",
    "jorgeCV = \"./CV-JorgeBoretto.pdf\"\n",
    "\n",
    "cloader = PyPDFLoader(miCV)\n",
    "cdocs = cloader.load()\n",
    "\n",
    "jloader = PyPDFLoader(jorgeCV)\n",
    "jdocs = jloader.load()\n",
    "\n",
    "# Genero los chunks \n",
    "cchunks = chunkData(cdocs, chunk_size=500, chunk_overlap=100)\n",
    "jchunks = chunkData(jdocs, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2bd31-5b04-4bdc-8a07-4af02f086e1a",
   "metadata": {},
   "source": [
    "### Generaci√≥n de embbeding y carga en base de datos vectorial\n",
    "Se utilizara un indice por cada uno de los cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc532d10-6cd5-46e1-956b-a77287855eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dd8573-5ecf-460b-9ca8-cbb17381256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='1.env')\n",
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41be9cb0-d296-4dbe-98d1-c8d2cc9f1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to DB Pinecone\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "cloud = 'aws'\n",
    "region = 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "indices = ['cagent', 'jagent']\n",
    "namespace = \"espacio\"\n",
    "dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a8ebbe-ddb5-4c5b-8885-850c370df084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ragllm', 'tp2llm', 'jagent', 'cagent']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bfce94-c977-4120-9af6-f6a4ce60537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index cagent borrado\n",
      "index creado con el nombre: cagent\n",
      "index jagent borrado\n",
      "index creado con el nombre: jagent\n"
     ]
    }
   ],
   "source": [
    "# Elimino el indice si es que ya existe en la base de datos\n",
    "for index_name in indices:\n",
    "    if index_name in pc.list_indexes().names():\n",
    "      pc.delete_index(index_name)\n",
    "      print(\"index {} borrado\".format(index_name))\n",
    "    \n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        # Como lo borre en el paso anterior siempre deberia entrar aca\n",
    "        print(\"index creado con el nombre: {}\".format(index_name))\n",
    "        pc.create_index(\n",
    "            index_name,\n",
    "            dimension=dimension, \n",
    "            metric='cosine',\n",
    "            spec=spec\n",
    "            )\n",
    "    else:\n",
    "        print(\"el index con el nombre {} ya estaba creado\".format(index_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3075029-aa98-4b1b-8c75-df90ab08c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Intel Core I5 10400\\AppData\\Local\\Temp\\ipykernel_10780\\1365815625.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Cargo un modelo de embeddings compatible\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2ec3d1-f0ff-4178-bd68-090202ae7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upserted values to 'cagent' index\n"
     ]
    }
   ],
   "source": [
    "# Cargo chunks en base de datos\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=cchunks,\n",
    "    index_name='cagent',\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(\"upserted values to 'cagent' index\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad50f96-4b6f-4e22-b744-b612fe8b71db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upserted values to 'jagent' index\n"
     ]
    }
   ],
   "source": [
    "# Cargo chunks en base de datos\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=jchunks,\n",
    "    index_name='jagent',\n",
    "    embedding=embedding_model, \n",
    "    namespace=namespace\n",
    ")\n",
    "print(\"upserted values to 'jagent' index\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe953b8-c08a-4a6d-b2ac-edb1a8bc96db",
   "metadata": {},
   "source": [
    "### Busquedas en base de datos\n",
    "\n",
    "Realizo pruebas para verificar que los datos se guardaron correctamente\n",
    "\n",
    "## CRISTIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c878cd-d998-49e0-8d60-b1d02b900806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'espacio': {'vector_count': 9}},\n",
       " 'total_vector_count': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(indices[0])\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e78205-8240-4610-a6a9-1125930d79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=indices[0],\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8426fd24-c1b0-42bf-b4de-f4a6a5e914fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='02a1ebc7-30b3-4e0f-adcc-d8d30ccfe349', metadata={'page': 0.0, 'source': './CV_CristianMarino_CEIA_LLM.pdf'}, page_content='PYTHON                                  \\nPOWER BI                                \\nSenior Project Manager                                         Oct 2023 - Today\\nFECOVITA| Argentina\\nPMO Leader. Responsible for CAPEX portfolio management.\\nFormulation, feasibility study, bidding, execution and final audit of projects,\\nPresentation of Investment opportunities and funding proposals to the Board.\\nAchievements: 5 pre-approved projects. Currently, under bidding,\\nWORK EXPERIENCE'),\n",
       " Document(id='ccde11a9-8292-4282-9078-7ae674e80d5b', metadata={'page': 0.0, 'source': './CV_CristianMarino_CEIA_LLM.pdf'}, page_content='cristian.dam.marino@gmail.com\\n+ 54 9 2616504324\\nMendoza, Argentina\\nLANGUAGES AND TECH SKILLS\\nENGLISH                                                  (C1)\\nPORTUGUESE                                        (B2)\\nFRENCH                                                  (B1)\\nITALIAN                                                   (B1)\\nSQL                                           \\nPYTHON                                  \\nPOWER BI'),\n",
       " Document(id='1bf3fe03-9a29-4caf-972f-e04da3f3a842', metadata={'page': 0.0, 'source': './CV_CristianMarino_CEIA_LLM.pdf'}, page_content='vision, time series analysis, natural language processing and big data.\\nEDUCATION\\nMEng in Industrial Engineering                                                 2022 \\nUniversidad Nacional de Cuyo | Argentina\\nExchange programs in Chile and Bolivia. Volunteering experience in Brazil.\\nVP of Finance and Legal                                  Aug 2019 - Jul 2020\\nThe AIESEC Foundation | Chile\\nResponsible for overall legal, financial and audit management and strategy,')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Qu√© hace en Fecovita\"\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d90c9a-ecdf-4d61-a458-b70861e24ca8",
   "metadata": {},
   "source": [
    "#### Jorge Boretto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b270a5c7-3e99-4d6f-8568-a3eed7346c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'espacio': {'vector_count': 9}},\n",
       " 'total_vector_count': 9}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(indices[0])\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b08cdacb-ef12-4f7b-9e1f-899dab38f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "jvectorstore = PineconeVectorStore(\n",
    "    index_name=indices[1],\n",
    "    embedding=embedding_model,\n",
    "    namespace=namespace,\n",
    ")\n",
    "retriever=jvectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3497870-b84b-42a6-b416-1d452e63f97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='85558b05-ed92-40b4-a4a4-50b9e7252f8a', metadata={'page': 26.0, 'source': './CV-JorgeBoretto.pdf'}, page_content='y Matem√°ticas. Secretar√≠a de Graduados en Ciencias de la Salud, Universidad Nacional de C√≥rdoba. Duraci√≥n 20 hs. (aprobado). C√≥rdoba, Argentina.  IDIOMA  Franc√©s - 05.2003. Curso de Franc√©s Aprobado. Cours de Langue 1 de Fran√ßais Langue Etrang√®re. Alliance Fran√ßaise de C√≥rdoba. Duraci√≥n 39 hs. C√≥rdoba, Argentina.  Ingles - 12.2002. Examen de Ingl√©s Aprobado. Secretar√≠a de Graduados en Ciencias de la Salud, Universidad Nacional de C√≥rdoba. C√≥rdoba, Argentina. - 03.1999. Educaci√≥n Continua de'),\n",
       " Document(id='91475b1f-a390-408b-b915-ff60967f46fb', metadata={'page': 9.0, 'source': './CV-JorgeBoretto.pdf'}, page_content='para Cobertura de Grandes Defectos en Mano‚Äù. 38¬∫ Congreso Argentino de Cirug√≠a de la Mano. Mar del Plata, Argentina.  A√ëO 2011 √º ‚ÄúColgajos en Isla de la Mano‚Äù. Simposio: ‚ÄúColgajos en el Miembro Superior‚Äù. 48¬∞ Congreso Argentino de Ortopedia y Traumatolog√≠a. Buenos Aires, Argentina. √º ‚ÄúLesiones de Plexo Braquial‚Äù. III Curso de Revisi√≥n en Ortopedia General. 48¬∞ Congreso Argentino de Ortopedia y Traumatolog√≠a. Buenos Aires, Argentina. √º ‚Äú¬øC√≥mo Publicar?‚Äù. Curso de Instrucci√≥n Pr√°ctica: ¬øQu√© es'),\n",
       " Document(id='2a28fc58-48a3-49a4-99f5-38a3d62b56a2', metadata={'page': 26.0, 'source': './CV-JorgeBoretto.pdf'}, page_content='Argentina. √º III Jornadas de Educaci√≥n para Profesionales de la Salud: ‚ÄúNuevas Tecnolog√≠as para la formaci√≥n en Salud‚Äù. Hospital Italiano de Buenos Aires. Buenos Aires, Argentina. √º Curso: ‚ÄúPreparaci√≥n, dise√±o y presentaci√≥n de un trabajo cient√≠fico‚Äù. Asociaci√≥n Argentina de Cirug√≠a de la Mano y Reconstructiva del Miembro Superior. Buenos Aires, Argentina.  A√ëO 2007 √º Curso de Postgrado de Epidemiolog√≠a y Estad√≠stica. Instituto Universitario, Escuela de Medicina del Hospital Italiano. Duraci√≥n')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Cuales es su educacion?\"\n",
    "jvectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edea2d-fc41-4c4b-a1f6-eed59329529a",
   "metadata": {},
   "source": [
    "## Agente LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229bde6f-a3e0-43fc-ab95-01fc3420c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (0.2.59)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph) (0.3.24)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph) (2.0.9)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph) (0.1.44)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.2.3)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\intel core i5 10400\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
      "Requirement already satisfied: anyio in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\intel core i5 10400\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad56ff5-490d-47af-a661-0854ae7e8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1624e699-7d8a-4742-9715-48e17aea6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0766d7b4-ad29-4acb-8eaf-6b522ff6e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY, \n",
    "    model_name='llama3-8b-8192'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af742fa-c7d6-4538-86e4-2207020f9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una clase para guardar el estado \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    individual: str\n",
    "    history: List[str] \n",
    "\n",
    "# Defino un tamplate para el prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"individual\"],\n",
    "    template=\"\"\"\n",
    "Eres un asistente para tareas de preguntas y respuestas. Usa los siguientes fragmentos de historia y contexto recuperados para responder la pregunta respecto al individuo.\n",
    "Si no sabes la respuesta, di que no lo sabes. Usa un m√°ximo de 200 palabras y mant√©n la respuesta concisa. \n",
    "---\n",
    "Historia:\n",
    "{history}\n",
    "---\n",
    "Contexto:\n",
    "{context}\n",
    "---\n",
    "Individuo:\n",
    "{individual}\n",
    "---\n",
    "Pregunta: {question}\n",
    "Respuesta:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Defino una clase agente para hacer la busqueda en la base vectorial segun la persona\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, embedding_model, index=\"\"):\n",
    "        if index==\"\":\n",
    "            raise ValueError(\"No se especifico un √≠ndice v√°lido.\")\n",
    "        \n",
    "        self.index = index\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        self.vectorstore = PineconeVectorStore(\n",
    "            index_name=index,\n",
    "            embedding=self.embedding_model,\n",
    "            namespace=namespace,\n",
    "        )\n",
    "\n",
    "    def get_context(self,state: State):\n",
    "        retrieved_docs = self.vectorstore.similarity_search(state[\"question\"],k=2)\n",
    "        return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "832b4a22-0005-46ad-ace7-cdff1c943310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancio agentes\n",
    "cagent = Agent(embedding_model,\"cagent\")\n",
    "jagent = Agent(embedding_model,\"jagent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bb6f15d-edce-42d0-a318-b48610cb31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los nodos para el agente\n",
    "def generate(state: State):\n",
    "    if state[\"context\"]:\n",
    "        docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    else: \n",
    "        docs_content = \"\"\n",
    "    # Formateo la historia como un unico string\n",
    "    history = \"\\n\".join(state[\"history\"])\n",
    "    \n",
    "    # Invoco el prompt con contexto e historia previa\n",
    "    messages = prompt.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content,\n",
    "        \"individual\": state[\"individual\"],\n",
    "        \"history\": history\n",
    "    })\n",
    "\n",
    "    # print(messages)\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    state[\"history\"].append(f\"Q: {state['question']} A: {response.content}\")\n",
    "    \n",
    "    # Ahora ya es posible devolver la respuesta\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Nodo para limpiar el contexto\n",
    "def empty_context(state:State):\n",
    "    return {\"context\":[]}\n",
    "\n",
    "# Segun sobre a quien se refiere la pregunta se utiliza un agente u otro\n",
    "def decide(state: State):\n",
    "    \n",
    "    cristian_pattern = r\"(Cristian\\sMarino|Cristian|Marino)\"\n",
    "    jorge_pattern = r\"(Jorge\\sBoretto|Jorge|Boretto)\"\n",
    "    individual = \"\" \n",
    "    \n",
    "    if re.search(cristian_pattern, state[\"question\"], re.IGNORECASE):\n",
    "        individual = \"cristian\"\n",
    "    elif re.search(jorge_pattern, state[\"question\"], re.IGNORECASE):\n",
    "        individual = \"jorge\"\n",
    "    return {\"individual\":individual}\n",
    "\n",
    "# Funcion para determinar cu√°l es el pr√≥ximo nodo\n",
    "def decision_read_state(state:State):\n",
    "    \"\"\"Obtiene el individuo desde el state y lo retorna para decidir por qu√© nodo continuar.\"\"\"\n",
    "    indiv = state[\"individual\"]\n",
    "    if indiv==\"\":\n",
    "        print(\"La pregunta no habla de ningun individuo.\")\n",
    "        return \"no_individual\"\n",
    "    print(\"La pregunta habla sobre el individuo:\",indiv)\n",
    "    return indiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4d0da0-12f0-483c-8e45-537a964026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo el grafo de nodos\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"decision\",decide)\n",
    "graph_builder.add_node(\"cristian_agent\",cagent.get_context)\n",
    "graph_builder.add_node(\"jorge_agent\",jagent.get_context)\n",
    "graph_builder.add_node(\"generate\",generate)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"decision\",\n",
    "    decision_read_state,\n",
    "    {\"cristian\": \"cristian_agent\",\"jorge\": \"jorge_agent\",\"no_individual\":\"cristian_agent\"}\n",
    "    )\n",
    "graph_builder.add_edge(\"cristian_agent\",\"generate\")\n",
    "graph_builder.add_edge(\"jorge_agent\",\"generate\")\n",
    "graph_builder.set_entry_point(\"decision\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4811-86f8-4630-8a46-1b32d495305a",
   "metadata": {},
   "source": [
    "## No me sale usar graph viz, ni json, ni networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc52747-75f7-4953-8276-f77df905d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dot(graph):\n",
    "    dot_representation = 'digraph G {\\n'\n",
    "    for node_id, node in graph.nodes.items():\n",
    "        dot_representation += f'    \"{node_id}\"\\n'\n",
    "    for edge in graph.edges:\n",
    "        if edge.conditional:\n",
    "            dot_representation += f'    \"{edge.source}\" -> \"{edge.target}\" [label=\"{edge.data}\"]\\n'\n",
    "        else:\n",
    "            dot_representation += f'    \"{edge.source}\" -> \"{edge.target}\"\\n'\n",
    "    dot_representation += '}'\n",
    "    return dot_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2aa1dc8-687d-482a-b9bf-5369139b391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph G {\n",
      "    \"__start__\"\n",
      "    \"decision\"\n",
      "    \"cristian_agent\"\n",
      "    \"jorge_agent\"\n",
      "    \"generate\"\n",
      "    \"__start__\" -> \"decision\"\n",
      "    \"cristian_agent\" -> \"generate\"\n",
      "    \"jorge_agent\" -> \"generate\"\n",
      "    \"decision\" -> \"cristian_agent\" [label=\"cristian\"]\n",
      "    \"decision\" -> \"jorge_agent\" [label=\"jorge\"]\n",
      "    \"decision\" -> \"cristian_agent\" [label=\"no_individual\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Este formato lo utilizo en la pagina web para generar el grafico\n",
    "print(convert_to_dot(graph.get_graph()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91565557-0e03-44ac-9d30-58230bece17b",
   "metadata": {},
   "source": [
    "### Prueba del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9684f2d7-74b9-45b3-81a9-2375c31052c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta habla sobre el individuo: jorge\n",
      "S√≠, Jorge Boretto es m√©dico, seg√∫n se menciona en su perfil que trabaja en la Cl√≠nica de la Mano de Buenos Aires.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Jorge es m√©dico?\",\"history\":[]})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b75dc26-0851-4000-88cf-967cd567b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta habla sobre el individuo: cristian\n",
      "Cristian tiene experiencia en gesti√≥n general de legal, financiera y de auditor√≠a, y ha liderado 6 equipos. Ha trabajado con m√∫ltiples stakeholders y ha sido representante de la oficina chilena ante el Consejo Financiero de la Sede Central. Adem√°s, ha logrado varios logros notables, como la renegociaci√≥n de 5 contratos clave que llev√≥ a un crecimiento del 28% en la renta y un aumento de los reservas financieras en un 450%. Tambi√©n ha reducido el tiempo de cobro en 23 d√≠as.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Contame sobre la experiencia de Cristian\",\"history\":[]})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f1341d-2f6d-4c6f-b4b0-34bc1baae500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pregunta no habla de ningun individuo.\n",
      "No tengo informaci√≥n sobre el lugar de trabajo actual del individuo. Sin embargo, puedo mencionar que en el pasado fue VP de Finance and Legal en The AIESEC Foundation en Chile, desde agosto de 2019 hasta julio de 2020.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"D√≥nde trabaja?\",\"history\":[]})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb6036-cead-4b84-a5e1-8d65b1940ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
