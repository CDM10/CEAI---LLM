{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este ejemplo evaluamos tres modelos distintos pre-entrenados y finetuned de BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") predictions [1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1]\n",
      "model: DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") predictions [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "model: BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ") predictions [1 1 0 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1\n",
      " 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1]\n",
      "Modelo 1 (DistilBERT): 90/100 correctos\n",
      "Modelo 2 (ANE DistilBERT): 47/100 correctos\n",
      "Modelo 3 (BERT): 93/100 correctos\n",
      "\n",
      "Ejemplos correctos para Modelo 1 (DistilBERT):\n",
      "Texto: <br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\n",
      "Predicci√≥n: 1, Etiqueta: 1\n",
      "\n",
      "Texto: This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\n",
      "Predicci√≥n: 1, Etiqueta: 1\n",
      "\n",
      "Ejemplos incorrectos para Modelo 1 (DistilBERT):\n",
      "Texto: I was truly and wonderfully surprised at \"O' Brother, Where Art Thou?\" The video store was out of all the movies I was planning on renting, so then I came across this. I came home and as I watched I became engrossed and found myself laughing out loud. The Coen's have made a magnificiant film again. But I think the first time you watch this movie, you get to know the characters. The second time, now that you know them, you laugh sooo hard it could hurt you. I strongly would reccomend ANYONE seeing this because if you are not, you are truly missing a film gem for the ages. 10/10\n",
      "Predicci√≥n: 0, Etiqueta: 1\n",
      "\n",
      "Texto: A holiday on a boat, a married couple, an angry waiter and a shipwreck is the reason to this films beginning.<br /><br />I like boobs. No question about that. But when the main character allies with whoever happens to have the most fish at the moment, mostly by having sex with them and playing the role of the constant victim, my anger just rises to a whole new level. Take two guys (a husband and another man), put a pure bombshell woman in the middle of them, ad a deserted island, subtract all her moral issues, ad a whole bunch of moral issues to the men and mix it in a big bowl of arguments, fish and a zippo lighter and you will come up with a piece of junk movie like this. <br /><br />The acting is, I would say, good. There are some bloopers but not many as far as i could see. The main female character makes me sick. This is due to her lack of moral values. The man with the most fish get's her attention. Even though one of them is her husband, she sees no problem with being unfaithful with (Manuel) the other man because \"I must do it to survive\". How can you justify having sex with another man for fish when your husband is 30feet away? And he won't even benefit from it? The female character has absolutely no problems to justify anything that she does. If she doesen't get approval for her actions, she's a victim.<br /><br />I recommend everyone to see this movie. This is the kind of movie that will make just about everything else you see this year a pleasant movie experience.\n",
      "Predicci√≥n: 1, Etiqueta: 0\n",
      "\n",
      "\n",
      "Ejemplos correctos para Modelo 2 (ANE DistilBERT):\n",
      "Texto: <br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\n",
      "Predicci√≥n: 1, Etiqueta: 1\n",
      "\n",
      "Texto: This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\n",
      "Predicci√≥n: 1, Etiqueta: 1\n",
      "\n",
      "Ejemplos incorrectos para Modelo 2 (ANE DistilBERT):\n",
      "Texto: This movie was so frustrating. Everything seemed energetic and I was totally prepared to have a good time. I at least thought I'd be able to stand it. But, I was wrong. First, the weird looping? It was like watching \"America's Funniest Home Videos\". The damn parents. I hated them so much. The stereo-typical Latino family? I need to speak with the person responsible for this. We need to have a talk. That little girl who was always hanging on someone? I just hated her and had to mention it. Now, the final scene transcends, I must say. It's so gloriously bad and full of badness that it is a movie of its own. What crappy dancing. Horrible and beautiful at once.\n",
      "Predicci√≥n: 1, Etiqueta: 0\n",
      "\n",
      "Texto: This movie spends most of its time preaching that it is the script that makes the movie, but apparently there was no script when they shot this waste of time! The trailer makes this out to be a comedy, but the film can't decide if it wants to be a comedy, a drama, a romance or an action film. Press releases indicated that Shatner and Hamlin made this movie because they loved the script (what were they thinking?). If you like William Shatner (I do) see \"Free Enterprise\" instead.\n",
      "Predicci√≥n: 1, Etiqueta: 0\n",
      "\n",
      "\n",
      "Ejemplos correctos para Modelo 3 (BERT):\n",
      "Texto: <br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\n",
      "Predicci√≥n: 1, Etiqueta: 1\n",
      "\n",
      "Texto: This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\n",
      "Predicci√≥n: 1, Etiqueta: 1\n",
      "\n",
      "Ejemplos incorrectos para Modelo 3 (BERT):\n",
      "Texto: \"An astronaut (Michael Emmet) dies while returning from a mission and his body is recovered by the military. The base where the dead astronaut is taken to becomes the scene of a bizarre invasion plan from outer space. Alien embryos inside the dead astronaut resurrect the corpse and begin a terrifying assault on the military staff in the hopes of conquering the world,\" according to the DVD sleeve's synopsis.<br /><br />A Roger Corman \"American International\" production. The man who fell to Earth impregnated, Mr. Emmet (as John Corcoran), does all right. Angela Greene is his pretty conflicted fianc√©e. And, Ed Nelson (as Dave Randall) is featured as prominently. With a bigger budget, better opening, and a re-write for crisper characterizations, this could have been something approaching classic 1950s science fiction.<br /><br />*** Night of the Blood Beast (1958) Bernard L. Kowalski, Roger Corman ~ Michael Emmet, Angela Greene, Ed Nelson\n",
      "Predicci√≥n: 1, Etiqueta: 0\n",
      "\n",
      "Texto: I remember seeing this film in the mid 80's thought it a well paced and well acted piece. I now work quite often in Berkeley Square and the had to get a copy of DVD to remind myself how little the area has changed, although my office is newish it just 30 seconds away from \"the bank\". Even Jack Barclays car dealership is still there selling Bentleys and Rolls Royces.<br /><br />It's look like the DVD is due a Region 2 release soon. The region 1 copy I is very poor quality. Let's hope they've cleaned it up.<br /><br />Only the slightly dodgy escape sequence from the court spoils what would otherwise be a great film but I guess is in line with the caper tag the film goes with.\n",
      "Predicci√≥n: 0, Etiqueta: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configurar el logging para evitar mensajes de advertencia\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Cargar el conjunto de datos de SST-2\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Mezclar el conjunto de datos\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Cargar los modelos y los tokenizers\n",
    "model1_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model2_name = \"apple/ane-distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model3_name = \"echarlaix/bert-large-uncased-whole-word-masking-finetuned-sst-2\"\n",
    "\n",
    "tokenizer1 = DistilBertTokenizer.from_pretrained(model1_name)\n",
    "tokenizer2 = DistilBertTokenizer.from_pretrained(model2_name)\n",
    "tokenizer3 = BertTokenizer.from_pretrained(model3_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model1 = DistilBertForSequenceClassification.from_pretrained(model1_name, ignore_mismatched_sizes=True).to(device)\n",
    "model2 = DistilBertForSequenceClassification.from_pretrained(model2_name, ignore_mismatched_sizes=True).to(device)\n",
    "model3 = BertForSequenceClassification.from_pretrained(model3_name, ignore_mismatched_sizes=True).to(device)\n",
    "\n",
    "# Funci√≥n para hacer inferencias\n",
    "def evaluate_model(model, tokenizer, texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = outputs.logits.argmax(dim=-1).cpu().numpy()  # Convertir a numpy\n",
    "    print(\"model:\", model, \"predictions\", predictions)\n",
    "    return predictions\n",
    "\n",
    "# Evaluar los modelos\n",
    "# Evaluate the model on the test set\n",
    "texts = dataset['test']['text'][:100]  # Get the first 100 reviews\n",
    "labels = dataset['test']['label'][:100]  # Corresponding labels\n",
    "\n",
    "predictions1 = evaluate_model(model1, tokenizer1, texts)\n",
    "predictions2 = evaluate_model(model2, tokenizer2, texts)\n",
    "predictions3 = evaluate_model(model3, tokenizer3, texts)\n",
    "\n",
    "# Comparar resultados\n",
    "correct_predictions1 = (predictions1 == labels).sum()\n",
    "correct_predictions2 = (predictions2 == labels).sum()\n",
    "correct_predictions3 = (predictions3 == labels).sum()\n",
    "\n",
    "print(f\"Modelo 1 (DistilBERT): {correct_predictions1}/100 correctos\")\n",
    "print(f\"Modelo 2 (ANE DistilBERT): {correct_predictions2}/100 correctos\")\n",
    "print(f\"Modelo 3 (BERT): {correct_predictions3}/100 correctos\")\n",
    "\n",
    "# Funci√≥n para imprimir ejemplos correctos e incorrectos\n",
    "def print_examples(predictions, labels, texts, model_name):\n",
    "    correct_indices = [i for i in range(len(predictions)) if predictions[i] == labels[i]]\n",
    "    incorrect_indices = [i for i in range(len(predictions)) if predictions[i] != labels[i]]\n",
    "\n",
    "    print(f\"\\nEjemplos correctos para {model_name}:\")\n",
    "    for idx in correct_indices[:2]:  # Imprimir 2 ejemplos correctos\n",
    "        print(f\"Texto: {texts[idx]}\")\n",
    "        print(f\"Predicci√≥n: {predictions[idx]}, Etiqueta: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"Ejemplos incorrectos para {model_name}:\")\n",
    "    for idx in incorrect_indices[:2]:  # Imprimir 2 ejemplos incorrectos\n",
    "        print(f\"Texto: {texts[idx]}\")\n",
    "        print(f\"Predicci√≥n: {predictions[idx]}, Etiqueta: {labels[idx]}\\n\")\n",
    "\n",
    "# Imprimir ejemplos para todos los modelos\n",
    "print_examples(predictions1, labels, texts, \"Modelo 1 (DistilBERT)\")\n",
    "print_examples(predictions2, labels, texts, \"Modelo 2 (ANE DistilBERT)\")\n",
    "print_examples(predictions3, labels, texts, \"Modelo 3 (BERT)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspeccionamos el dataset GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas\n",
    "from datasets import load_dataset\n",
    "\n",
    "# \"MRPC\" se refiere a Microsoft Research Paraphrase Corpus, \n",
    "# que es uno de los subtareas dentro del conjunto de datos \n",
    "# GLUE (General Language Understanding Evaluation). \n",
    "# MRPC est√° dise√±ado para evaluar la capacidad de los modelos de \n",
    "# lenguaje para identificar si dos oraciones son par√°frasis una de la otra.\n",
    "glue_dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "# Ver las caracter√≠sticas del dataset\n",
    "print(glue_dataset)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(glue_dataset['train'][0])  # Mostrar el primer ejemplo del conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# SST-2, que significa Stanford Sentiment Treebank 2. \n",
    "# Esta tarea se centra en la clasificaci√≥n de sentimientos \n",
    "sst2_dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Ver las caracter√≠sticas del dataset\n",
    "print(sst2_dataset)\n",
    "\n",
    "# Mostrar ejemplos del conjunto de entrenamiento\n",
    "print(\"Ejemplo del conjunto de entrenamiento:\")\n",
    "print(sst2_dataset['train'][0])  # Mostrar el primer ejemplo del conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluaci√≥n de CHATGPT 4O mini en SuperGLUE en la tarea RTE \n",
    "##### eval√∫a la comprensi√≥n del lenguaje natural, determinando si una hip√≥tesis se puede inferir de una premisa dada\n",
    "##### Probar con distintos modelos y con DEBAG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "def load_rte_data(split=\"validation\", n_samples=20):\n",
    "    \"\"\"\n",
    "    Carga el dataset RTE de SuperGLUE\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\n",
    "        \"super_glue\", \n",
    "        \"rte\",\n",
    "        trust_remote_code=True\n",
    "    )[split]\n",
    "    \n",
    "    if n_samples:\n",
    "        dataset = dataset.select(range(min(n_samples, len(dataset))))\n",
    "    return dataset\n",
    "\n",
    "def format_prompt(premise, hypothesis):\n",
    "    \"\"\"\n",
    "    Formatea el prompt para la tarea RTE con instrucciones m√°s claras\n",
    "    \"\"\"\n",
    "    return f\"\"\"Dado el siguiente par de oraciones, tu tarea es determinar si la segunda oraci√≥n (hip√≥tesis) \n",
    "se puede inferir l√≥gicamente de la primera oraci√≥n (premisa).\n",
    "\n",
    "Premisa: {premise}\n",
    "\n",
    "Hip√≥tesis: {hypothesis}\n",
    "\n",
    "Si la hip√≥tesis se puede inferir l√≥gicamente de la premisa, responde exactamente con la palabra: entailment\n",
    "Si la hip√≥tesis NO se puede inferir l√≥gicamente de la premisa, responde exactamente con la palabra: not_entailment\n",
    "\n",
    "Responde solo con una de estas dos palabras: entailment o not_entailment\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "def get_model_prediction(client, premise, hypothesis, debug=True):\n",
    "    \"\"\"\n",
    "    Obtiene la predicci√≥n del modelo usando la API de OpenAI\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-16k\", #\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Eres un asistente experto en l√≥gica y razonamiento. Tu tarea es determinar si una hip√≥tesis se puede inferir l√≥gicamente de una premisa dada.\"},\n",
    "                {\"role\": \"user\", \"content\": format_prompt(premise, hypothesis)}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        prediction = response.choices[0].message.content.strip().lower()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nPremisa: {premise}\")\n",
    "            print(f\"Hip√≥tesis: {hypothesis}\")\n",
    "            print(f\"Predicci√≥n raw: {prediction}\")\n",
    "        \n",
    "        # Normalizaci√≥n m√°s estricta de la respuesta\n",
    "        if prediction == 'entailment':\n",
    "            return 'entailment'\n",
    "        elif prediction == 'not_entailment':\n",
    "            return 'not_entailment'\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Respuesta no v√°lida del modelo: {prediction}\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la API: {e}\")\n",
    "        time.sleep(20)\n",
    "        return None\n",
    "\n",
    "def evaluate_model(client, dataset, debug=True):\n",
    "    \"\"\"\n",
    "    Eval√∫a el modelo en el dataset RTE con capacidades de depuraci√≥n\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    examples_info = []\n",
    "    \n",
    "    # Label map correcto seg√∫n el dataset de SuperGLUE\n",
    "    label_map = {0: 'entailment', 1: 'not_entailment'}\n",
    "    \n",
    "    for idx, example in enumerate(tqdm(dataset)):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        true_label = label_map[example['label']]\n",
    "        \n",
    "        pred = get_model_prediction(client, premise, hypothesis, debug=debug)\n",
    "        \n",
    "        if pred is not None:\n",
    "            predictions.append(pred)\n",
    "            true_labels.append(true_label)\n",
    "            \n",
    "            # Guardar informaci√≥n del ejemplo para an√°lisis\n",
    "            examples_info.append({\n",
    "                'idx': idx,\n",
    "                'premise': premise,\n",
    "                'hypothesis': hypothesis,\n",
    "                'true_label': true_label,\n",
    "                'predicted': pred,\n",
    "                'correct': pred == true_label\n",
    "            })\n",
    "            \n",
    "        time.sleep(1)\n",
    "    \n",
    "    return predictions, true_labels, examples_info\n",
    "\n",
    "def analyze_results(examples_info):\n",
    "    \"\"\"\n",
    "    Analiza los resultados de la evaluaci√≥n en detalle\n",
    "    \"\"\"\n",
    "    correct_examples = [ex for ex in examples_info if ex['correct']]\n",
    "    incorrect_examples = [ex for ex in examples_info if not ex['correct']]\n",
    "    \n",
    "    print(f\"\\nTotal de ejemplos evaluados: {len(examples_info)}\")\n",
    "    print(f\"Ejemplos correctos: {len(correct_examples)}\")\n",
    "    print(f\"Ejemplos incorrectos: {len(incorrect_examples)}\")\n",
    "    \n",
    "    print(\"\\nEjemplos de predicciones incorrectas:\")\n",
    "    for i, example in enumerate(incorrect_examples[:3]):  # Mostrar los primeros 3 errores\n",
    "        print(f\"\\nError {i+1}:\")\n",
    "        print(f\"Premisa: {example['premise']}\")\n",
    "        print(f\"Hip√≥tesis: {example['hypothesis']}\")\n",
    "        print(f\"Etiqueta verdadera: {example['true_label']}\")\n",
    "        print(f\"Predicci√≥n: {example['predicted']}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "def main():\n",
    "    # Inicializar cliente de OpenAI\n",
    "    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    \n",
    "    # Cargar datos\n",
    "    print(\"Cargando dataset...\")\n",
    "    dataset = load_rte_data(split=\"validation\", n_samples=20)  # Reducir muestras para depuraci√≥n\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    print(\"Evaluando modelo...\")\n",
    "    predictions, true_labels, examples_info = evaluate_model(client, dataset, debug=False)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    report = classification_report(true_labels, predictions)\n",
    "    \n",
    "    # Analizar resultados\n",
    "    analyze_results(examples_info)\n",
    "    \n",
    "    # Guardar resultados detallados\n",
    "    results = {\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"classification_report\": report,\n",
    "        \"examples_info\": examples_info\n",
    "    }\n",
    "    \n",
    "    with open(\"evaluation_results_detailed.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"\\nResultados finales:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nReporte de clasificaci√≥n:\")\n",
    "    print(report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
